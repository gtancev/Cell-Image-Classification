{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ML libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# helper libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# define line width and font size of plots\n",
    "plt.rcParams['lines.linewidth'] = 1.0\n",
    "plt.rcParams['font.size'] = 6.0\n",
    "plt.rcParams['axes.titlesize'] = 6.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing Definition\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25998 images belonging to 2 classes.\n",
      "Found 1560 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Load Images and Preprocessing (Resize, Scale, Batch Size Definition)\n",
    "img_size = 30\n",
    "batch_size = 32\n",
    "\n",
    "training_set = train_datagen.flow_from_directory('train',\n",
    "                                                 target_size = (img_size, img_size),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'binary',\n",
    "                                                 color_mode = 'rgb')\n",
    " \n",
    "test_set = test_datagen.flow_from_directory('test',\n",
    "                                            target_size = (img_size, img_size),\n",
    "                                            batch_size = batch_size,\n",
    "                                            class_mode = 'binary',\n",
    "                                            color_mode = 'rgb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape is (batch size, height, width, channels): (32, 30, 30, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAO4AAAD1CAYAAABX/8l6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAEQtJREFUeJzt3VuspfVZx/Hfu4577zWHPTAz7QAzLSC1eGE8xbYWT4kxKQIXJMaqEauJbUoIMRq1TUMU08RKNTCgeKAKSW0rYKnRaFOjtU1L0lbBeKFY6TAWigzMYc/s0zq9By+YxsTw/BZ7j3vPPMP3c0PIM+9hvWv/1prsZ57/v2iaRgByaZ3vGwCwcQQXSIjgAgkRXCAhggskRHCBhAjua1hRFPec73vA5nTO9w3g1SuK4u2S3iFpXtKypM9Jul7ShyT9jKRvlXS3pF+W9B+SvkPSk5LeIum9kh6U9Jik75L0vrPn3CvpA5JOSHqqaZrHtu0FYdMIbi7vlPSvejm4X5f0cUnfefb/W5JelPQ2SZWkeyXdKenPJa1JulLSWtM0Hy+K4oCkq86e84cklZKel3TFdr0QnBv+qpzLI3o5cJWkd0n6EUnv18uhbJ/9M21JZfPyP4mrJU3P/rclab4oivecPcczZ//85yX1JQ0k/cu2vAqcs4J/8vjaURTFPU3T/OL5vg+cO4ILJMRflYGECC6QEMEFEiK4QEIb6uMWRbHp32R1Ou2wduWVh+JrqghrdT3rqvGxm1XX/hE09p42dz/FjI/XwpzW1VT4B/i1rx31F8aWaJpm5g/Khn6rfC7B3b//0rD2sT+7L6y11AtrozV/zcYEpSjiD5Kqil/meFTaa5Yjd0Mmga241un65Hb78f12e3E4m9bYnveGm37S1rE1Xk1w+asykBDBBRIiuEBCBBdIaNumgw4f/vWwdsn+xbB24hvDsDZe9Z87de1+ORXXGndc07XXLMwvtsrS/BbX/LZ6Wk/tNced+DkULfOLthm/arxkT/wLxbKKf0m3vHzGnxjnjG9cICGCCyREcIGECC6QEMEFEiK4QEIEF0ho24YMPvHwH4e1fXveENaWTB93MqrsNbuteJCgY3qfjel9zvr338P1iamafqsZeihLP9hQmzEp95b15uMBjpcPjp/vkWePhLUPfviOsFbX/j2b9VpfCxgyAC5SBBdIiOACCRFcICGCCyREcIGENtQOetM1Vzf3Hv7QK59oxi+wX/psPJq2/OX4uP7BeOTvsnfM22uOhvGiVM0kbju03RpPbf9Cjx87barxFOVg1yCslVPfImnMSGCnF7eZCtMSk/S/uxG9gtqsijdVvPDW41/5rL3knzz4gL+n1wDaQcBFiuACCRFcICGCCyREcIGECC6Q0IZWeey029q7uHtTFzr2X0thbXwkbhX1dsS3uLDT/9a8UjyJMh7H15yux+ed37Vgr7lv/56wNjLbl7gGwIyBGlVl/Acqc3Cv51esXDsTt3Va3fjYzlxce9t3/6C95nU/8L1h7ZFHHw5rn/7bv7fnvdjwjQskRHCBhAgukBDBBRIiuEBCBBdIaEPTQYOFhebaN1/zirVZZ7mh/Omw9tjT8a/5f+NnfzesXfUL/qprp+MWVHkm7r+MluLPM9NFkiS1+nH7qqziiZrJxEzbzNidq5yaxeLa5rWs+z7TiWfj6aqWmTqa3x0vQrew239XzF8an3darIa137//cFh74sl/tte80DAdBFykCC6QEMEFEiK4QEIEF0iI4AIJEVwgoW3b9OuawbVh7ej602Hte656a1i7/9H322s2EzOWVsb91vHp+PPs6JNuFUdpPI6PXbg8Hgkcm82uKnNOSZpWcT925VT8DKZLZhlHSf1BP6y1F8yxrfh+irZfsbI7F7/WuUH8nj333NGwNmrW7TX/6KH7wtrxEy/ZY7cCfVzgIkVwgYQILpAQwQUSIrhAQgQXSGhDqzyei6fXntrUcV868sWwduedd9tj9++NV1y8/b23hLWyG7czmuGMjtgwbpOUw/i3/I0Zv2tmfLy2zO5cKy8Ow9rkJf/27zxkanvm4qJpMZrOlSSpHMcjiuMmPvjA/vhm26bFJEm9btz2ulDxjQskRHCBhAgukBDBBRIiuEBCBBdIaNvaQVvhM5/5gq2/71feHdYKM38xXjEnnfiJmlYR10drcaujmYtvyN2r5FfYnN8dTyRNVuLJIUlqz5kVF6t4ysfOkBX+uyJ+QpLZ20yNeUjVyJ1V+qmfiFcgve8P7wlro5F/fluJb1wgIYILJERwgYQILpAQwQUSIrhAQtu2WNxWWFzcZev/+A8fDWtlvJ+Vjj05CWunno5rkqQd82FpZKaOqm58ynbXf7425m2pp3GbZHnJL6K2sGMQ1sp6xnMIFDN6W0UrrrfMY2iZ4zrm2UrSpQfj9+zxJ/4mrN1z9x/4E28Si8UBFymCCyREcIGECC6QEMEFEiK4QEIEF0go9Vjfj13/w7Y+NZtlHT8S9yFPPjsOa6UZ25OkTs+s1jiN+7jTcVyrF3z7vDB9SjfuNtgd9y8lqa7jcThTsmOIs/q4dbW5a3a77n3x30/D5fjZ33TjDWFtq/q4rwbfuEBCBBdIiOACCRFcICGCCyREcIGELvh20Pe//a1h7Zduv9Uee+w/47G1U/8et4PqOn4s7UX/yCb1NK6txtccjeJVE3uF35TKjbvVZmXEYtZuYpZdyjGsuBbTrLrrJNXmIZSlb6etLcfvy5lT8f3ceNOPhrW//qu/s9c8V3zjAgkRXCAhggskRHCBhAgukBDBBRK64Fd5/MKn41X2Rqf8587Rx4+HtV4RT8bMmVX/Ju24bSNJ66a1sPLiMKyN1uPzzr8+3rhLktoD87aYlk9T+Ukd97Ox2Vo1ox3k7qhlWj5ulcdW27/OtunwXXIwHr1645vjn5Prvu96e02HVR6BixTBBRIiuEBCBBdIiOACCRFcIKELfjroG/92Oqw1J/zUTLVmpnxe1wtrUzPhU1Zm3EaSa3Z0F+P7be+ZC2vFjHepME2Uyt3vjOberEme8DjbKtr8pl+uWVSZMahOx/+ctE27aO1kfN4zJ+Ofk63GNy6QEMEFEiK4QEIEF0iI4AIJEVwgIYILJHRB9HEHC/HY2vwg7m9OS3/7C+34c2l9Eo/YVcvxOX0X1/dxW534ftrmXit7VqmuXd80Pq4q/YiiG6OrzOZc1ozecVObPq75mila8aZf5Yx7Lar4xPUwfsdXT9PHBbABBBdIiOACCRFcICGCCyREcIGELoh20P0fvius9ebikazRqbilI0nTKm53lKaFosK0B+w6hNKkjFd57PTjFQML07dxY3LSjNG9GffruNZMYzosbpXHwu3cJakxrS+3d1eniNtBmrk4qbknc+hoeVZzcOvwjQskRHCBhAgukBDBBRIiuEBCBBdIaNvaQYd/686wtrf3+rC2+sI4rFWlaQFImpuPX17X7KNVmc+z8cRPhJS1+Sw0rQU74WOv6NsvzqzWTG2matyxbqrIr+I447Vucs+5TT4eSVKnF7fwyukmJ6T+H/CNCyREcIGECC6QEMEFEiK4QEIEF0iI4AIJbaiPe/VVB3XXXb+6qQvtH8S92heeiMfzOtoV13b6z521pbgH3HIja+apdDq+d9ztxn2/iRkz7HfN7oHmOGlWP3aTO/lpxs565jFUlelJx1OPkqRu3zz81ubGBUfDGasxmh56uxXfz3BtxovZQnzjAgkRXCAhggskRHCBhAgukBDBBRLaUDuo3+/pmqsPbe5KTdzuOHpiJaztu2I+rA2u9Z87o3+Kd+9afiZusdSmJdFajNs9kmS7Raa1UJi2Tb/lr1kV8bOtO/HoWbUet8skyS2cWJtlHptp/L6smDFNSWoV8fsyuCx+DlUvPm469m2v4Urcjuxfthjfz2K8Id1W4xsXSIjgAgkRXCAhggskRHCBhAgukNCGV3lsms1tdNTpxp8R1YvxdMaLx0+HtTe9Za+95q6DcT9j+IJpH5jpll7bP7JxFU+iTM00yfoZMwG06q85Mbth9Q/FLZTujhkrLrp90Zr42Y5WzDTOjEGdVs9twBX/DHU68XHtHb6dVpdxvdePW239+fiaH3ngsL1mdORvfvB37HHfxDcukBDBBRIiuEBCBBdIiOACCRFcIKENtYMaNSrrTbaDzIJcw6V4OqM8Fd9iNfK3v+PgIL7mifg4d96W2UhMksqluN/RNqND3UHcWihL37YZPj+Kr7kcX3N+j38t07HZ9Mv8GHTMxl5ze81ua5Jac2YzsZ5bLM60inr++6kw70tTmykoM8n00EOfsNdsgu3NTpw4ZY/7Jr5xgYQILpAQwQUSIrhAQgQXSIjgAgkRXCChDfVxX3rplO77vY+9Yq1xM2CSfv6Wd4a12hxbnIlvcfyC/9yZ+7Z4JGvH5fGI3WQ5vuZkEvf1JEmtuN4fxPcztyvuJU7jhQYlSafX1uLb6ZrzDv17dvpYvCJj16xYWU3Nhmpz/t8B9E1PtTL/hqAZmfel43/MW6ZPXpqG9dyO+LxffPxL9prnim9cICGCCyREcIGECC6QEMEFEiK4QEIbagedPHlaDz30l5u60M03XR/W5hbiNklrGm+stPSVeLMwSdpnVjhszI5W45PxuNZwybczmsqsNjgwK12aVkdhxuQkafC6fljrDuLXOZmx6dfkTNwuqtvmfs2zbeSfX7eOjy0KtwJkXJr1/JoyvqdWO37Pdl4SP/etxjcukBDBBRIiuEBCBBdIiOACCRFcIKENb/q1WXUR/75+8ar5sDZ8Jm7NrB45Y6+559j++LxL8XnXzKqJw//200H1nFlV8Y1xW2I8ie/nzMn4fiRpfhC3zDr9+JpFy2+GtXNf/LneMp/5dlCs4yeSOmY6qG0mnVzDp9eLj5P8ypKDffFxf/GpT9rzbiW+cYGECC6QEMEFEiK4QEIEF0iI4AIJbVs7aFrH7Y4D1+0Ia8dG8UJovZ1+A6lOK75mx2wgtfNg3B4wHQlJ0spqPHEz1483IWuaeELq5MqqvWY3PlRqxa+zP/DtoJbZLKtlNtkqS9My890gtdtm0y9Tc8f1+v5N65ghn92Xx8c+cNuf2vNuJb5xgYQILpAQwQUSIrhAQgQXSIjgAgkRXCChbevjfvWpI2HtW246FNduuTSsNWZFQEmaTuNxuIXLzSjct8djhtN134g8+fwwrI3OxH3l1krcU913KO7/SlLjNvYyj6iu4vuRJLeoYmX68nbGzhdVu0avmRdsm75yq+V/Trpz8Xl3XeKa5OcP37hAQgQXSIjgAgkRXCAhggskRHCBhLatHXTHHXeHtQMH4tUY9+yMR/46XX/7Vxw6YKpxC2B1bT2sHT+xZK+5e++esNaej1sLZROPAy5e7jeXGk/M6pFl/DrL2re2KlOfjKfxcdP4uBlTfer14/fU7L+lwpy53fIrcy7ujZ/vkSNftceeL3zjAgkRXCAhggskRHCBhAgukBDBBRIqGrtD0//5w4XZues82LUrbhVJ0qOP3BvWqqoKa5/7/JfD2l13fcRe8+fedXNY+/GbbwxrSy9MwtrqyfheJWkyilsog4V416rR2E8HuUmeyThusayZlS7brqcjqT8XT0n1zWqNHbPK42DRTyQVO+MW33tuuz2sraz61Tc3q2kaf8PiGxdIieACCRFcICGCCyREcIGECC6QUOp2EGZ74LcfDGvzvUV77DTuUKmo48981yoq3Ap0khrzI9bumM3YenFt8TK/WNxtv3ZrWHv2uWftsVuBdhBwkSK4QEIEF0iI4AIJEVwgIYILJERwgYS2bZVHnB+3fuDdYe3RBx+2x06GcTtxuByP7vXNJluzNuBq6viahTm0t8OM9e2LRwUlqWX6wxcqvnGBhAgukBDBBRIiuEBCBBdIiOACCW10rO+4pK9v3e0Ar3lvaJomXprzrA0FF8CFgb8qAwkRXCAhggskRHCBhAgukBDBBRIiuEBCBBdIiOACCf0P/qZu172etwYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Sanity Check\n",
    "print('The shape is (batch size, height, width, channels):',training_set[0][0].shape)\n",
    "\n",
    "# Pick and Plot a Random Example\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "ax.set_title('example')\n",
    "ax.imshow(training_set[0][0][0])\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "plt.savefig('example',dpi=900,transparent=True,orientation='landscape',bbox_inches='tight')\n",
    "plt.savefig('example',dpi=900,transparent=True,orientation='landscape',bbox_inches='tight',format='pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_20 (Conv2D)           (None, 30, 30, 5)         140       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling (None, 15, 15, 5)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 15, 15, 10)        460       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling (None, 8, 8, 10)          0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 640)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1)                 641       \n",
      "=================================================================\n",
      "Total params: 1,241\n",
      "Trainable params: 1,241\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Model Definition\n",
    "\n",
    "training_set_size = 25998\n",
    "test_set_size = 1560\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Convolution2D(5,(3,3),input_shape=(img_size,img_size,training_set[0][0].shape[3]),padding='same',data_format='channels_last',activation='relu'),\n",
    "    keras.layers.MaxPooling2D((2, 2), padding='same'),\n",
    "    keras.layers.Convolution2D(10,(3,3),padding='same',data_format='channels_last',activation='relu'),\n",
    "    keras.layers.MaxPooling2D((2, 2), padding='same'),\n",
    "    keras.layers.Flatten(),\n",
    "    #keras.layers.Dense(10, activation = 'relu'), # if you have a good CPU/GPU :S\n",
    "    keras.layers.Dense(1, activation = 'sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=tf.train.AdamOptimizer(), \n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "813/812 [==============================] - 162s 199ms/step - loss: 0.6102 - acc: 0.6696 - val_loss: 0.5731 - val_acc: 0.6641\n",
      "Epoch 2/10\n",
      "813/812 [==============================] - 149s 184ms/step - loss: 0.4816 - acc: 0.7797 - val_loss: 0.3443 - val_acc: 0.8346\n",
      "Epoch 3/10\n",
      "813/812 [==============================] - 151s 186ms/step - loss: 0.3643 - acc: 0.8455 - val_loss: 0.2405 - val_acc: 0.8910\n",
      "Epoch 4/10\n",
      "813/812 [==============================] - 155s 191ms/step - loss: 0.2866 - acc: 0.8861 - val_loss: 0.1806 - val_acc: 0.9340\n",
      "Epoch 5/10\n",
      "813/812 [==============================] - 144s 177ms/step - loss: 0.2409 - acc: 0.9101 - val_loss: 0.1723 - val_acc: 0.9327\n",
      "Epoch 6/10\n",
      "813/812 [==============================] - 147s 181ms/step - loss: 0.2167 - acc: 0.9222 - val_loss: 0.1418 - val_acc: 0.9545\n",
      "Epoch 7/10\n",
      "813/812 [==============================] - 149s 184ms/step - loss: 0.1988 - acc: 0.9304 - val_loss: 0.1385 - val_acc: 0.9487\n",
      "Epoch 8/10\n",
      "813/812 [==============================] - 153s 188ms/step - loss: 0.1913 - acc: 0.9331 - val_loss: 0.1240 - val_acc: 0.9596\n",
      "Epoch 9/10\n",
      "813/812 [==============================] - 149s 184ms/step - loss: 0.1823 - acc: 0.9361 - val_loss: 0.1068 - val_acc: 0.9641\n",
      "Epoch 10/10\n",
      "813/812 [==============================] - 144s 177ms/step - loss: 0.1779 - acc: 0.9390 - val_loss: 0.1131 - val_acc: 0.9647\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1c4c51b320>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model Fitting\n",
    "epochs = 5 # should lead to about 90% accuarcy\n",
    "\n",
    "model.fit_generator(training_set,\n",
    "                    steps_per_epoch = (training_set_size/batch_size),\n",
    "                    epochs = epochs,\n",
    "                    validation_data = test_set,\n",
    "                    validation_steps = (test_set_size/batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
